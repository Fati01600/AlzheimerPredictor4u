{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b3d52-1fd1-4ff3-97be-2a669b822469",
   "metadata": {},
   "source": [
    "# Notebook 02 – Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913c4a4-84b6-42cd-9615-2d1880b134df",
   "metadata": {},
   "source": [
    "This notebook prepares the Alzheimer's disease dataset so it can be used in analysis and machine learning.  \n",
    "We clean and transform the data to ensure high quality and usability.\n",
    "\n",
    "#### In this notebook we:\n",
    "- Load the dataset and take a first look at it.\n",
    "- Find and handle missing values.\n",
    "- Remove any duplicate rows.\n",
    "- Convert text categories into numbers so the computer can understand them. (encoding)\n",
    "- Organize the data in a way that makes it ready for analysis.\n",
    "\n",
    "The cleaned data we create here will be used in the next notebook for exploring patterns and building models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edde1b9-a127-47ed-aeea-8e806d2ddf54",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a26b0-a570-4fc3-9587-b6c2e4bb06bd",
   "metadata": {},
   "source": [
    "## Setup And Load Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966b09a-978f-42f5-8d00-6a7df0f3a3eb",
   "metadata": {},
   "source": [
    "To get started, we need to set up our working environment. For this, we use some helper functions that we have created and stored in a folder called utils. These helper functions help us:\n",
    "- Create folders to keep the project organized (such as data, models, plots, and reports)\n",
    "- Apply default chart styles using Seaborn\n",
    "- Load datasets and quickly explore them\n",
    "\n",
    "Along with that, we also import common libraries like Pandas, NumPy, Seaborn and Matplotlib, which we will be using throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "706074f3-c0d0-4682-bf64-f3db6e248616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete.\n",
      "All libraries imported and environment initialized.\n"
     ]
    }
   ],
   "source": [
    "# We are adding the parent folder to the Python path so we can import files from the \"utils\" folder\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Importing the custom helper functions from our project\n",
    "from utils.setup_notebook import (\n",
    "    init_environment,\n",
    "    load_csv,\n",
    "    print_shape,\n",
    "    print_info,\n",
    "    print_full_info,\n",
    "    print_description,\n",
    "    print_categorical_description,\n",
    "    show_head\n",
    ")\n",
    "from utils.save_tools import save_plot, save_notebook_and_summary\n",
    "\n",
    "# Importing commonly used libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Running environment setup\n",
    "init_environment()\n",
    "print(\"All libraries imported and environment initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10118cd-f219-4301-9059-2eba154f18ca",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a3e68-fe2a-44b8-9739-d4b0dff28930",
   "metadata": {},
   "source": [
    "## Extract – Load the Dataset\n",
    "\n",
    "In this step, we load the raw Alzheimer's dataset into our project using a custom helper function from our setup.py script. The dataset has not yet been cleaned or processed, this is the original version as collected.\n",
    "Our helper function uses pandas to read the CSV file and automatically provides basic metadata. \n",
    "\n",
    "### Including:\n",
    "- The file path from which the data was loaded.  \n",
    "- The number of rows and columns present in the dataset.  \n",
    "\n",
    "This step ensures that we have successfully accessed the correct dataset and gives us an initial understanding of its structure and scale before we proceed with cleaning and transformation. To keep the original intact, a working copy is also created. This ensures we can freely clean, explore, and manipulate the data without altering the raw file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6892794d-b69e-43aa-b106-629450f312a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from ../data/alzheimers_disease_raw_data.csv with shape (2149, 35)\n",
      "Copy of df_raw dataset created as 'df' succesfully\n"
     ]
    }
   ],
   "source": [
    "# We load the raw Alzheimer's dataset and save it as 'df_raw'\n",
    "df_raw = load_csv(\"../data/alzheimers_disease_raw_data.csv\")\n",
    "\n",
    "# Then create a working copy to avoid modifying the raw dataset directly\n",
    "df = df_raw.copy()\n",
    "print(\"Copy of df_raw dataset created as 'df' succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751db888-3016-4409-9515-2043a108d2fd",
   "metadata": {},
   "source": [
    "Thereafter save the working copy of the dataset to the project folder. This allows us to reuse it later without reloading or reprocessing the raw data each time. It also keeps the original dataset unchanged in case we need to go back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ad315d-a206-4b8e-8726-9c0c9a02c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ../data/alzheimers_raw_copy.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the copy of the dataset for future steps\n",
    "df.to_csv(\"../data/alzheimers_raw_copy.csv\", index=False)\n",
    "print(\"Dataset saved to ../data/alzheimers_raw_copy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dffddc-6746-4f50-adba-2699b71fac3c",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4dd86b-a144-42b1-a1d9-7a353df01bb1",
   "metadata": {},
   "source": [
    "### ELT Approach: Extract → Load → Transform\n",
    "\n",
    "In this project, we follow the ELT (Extract, Load, Transform) process to prepare the Alzheimer’s dataset for analysis and modeling.\n",
    "- **Extract**: We begin by accessing the raw dataset, which is provided in CSV format.\n",
    "- **Load**: Using pandas, we load the dataset into memory so it can be explored and manipulated.\n",
    "- **Transform**: We then clean and organize the data by checking for duplicates, handling missing values, removing unnecessary ID columns, and grouping features by type. These steps make the dataset ready for machine learning.\n",
    "\n",
    "This approach reflects a modern data workflow, where raw data is loaded first and then transformed in memory. It allows for faster iteration, flexible processing, and better reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b047e-20d7-4bff-8313-a0053f0c74ce",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c77cd4-1a51-4160-949b-70beae9f90e2",
   "metadata": {},
   "source": [
    "## Alternative Approach – Load Libraries\n",
    "\n",
    "Before we can work with the data, we need to import the necessary Python libraries:\n",
    "\n",
    "- **pandas** is used for handling tabular data (structured data in rows and columns, like a spreadsheet). It helps us load, clean, and manage datasets.\n",
    "- **numpy** is used for numerical operations, especially with arrays and mathematical functions.\n",
    "- **matplotlib.pyplot** and **seaborn** are used for visualizing data through plots and charts.\n",
    "\n",
    "After importing the libraries, we use `read_csv()` to load the dataset into a DataFrame called `df`, and use `head()` to preview the first five rows.\n",
    "\n",
    "This setup step is important because it gives us the tools needed for cleaning, exploring, and later modeling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "167f1374-baec-465e-998a-6e768a69617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported and environment initialized.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"All libraries imported and environment initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c2573d-a584-40a7-95cd-c8b5b46fa400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# We load the dataset\n",
    "dataframe = pd.read_csv(\"../data/alzheimers_disease_raw_data.csv\")\n",
    "print(\"Dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fdcd18-d70f-4406-86f5-50f13e852e33",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
