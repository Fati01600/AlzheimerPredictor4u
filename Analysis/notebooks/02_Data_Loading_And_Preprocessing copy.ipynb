{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b3d52-1fd1-4ff3-97be-2a669b822469",
   "metadata": {},
   "source": [
    "# Notebook 02 – Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913c4a4-84b6-42cd-9615-2d1880b134df",
   "metadata": {},
   "source": [
    "This notebook prepares the Alzheimer's disease dataset so it can be used in analysis and machine learning.  \n",
    "We clean and transform the data to ensure high quality and usability.\n",
    "\n",
    "#### In this notebook we:\n",
    "- Load the dataset and take a first look at it.\n",
    "- Find and handle missing values.\n",
    "- Remove any duplicate rows.\n",
    "- Convert text categories into numbers so the computer can understand them. (encoding)\n",
    "- Organize the data in a way that makes it ready for analysis.\n",
    "\n",
    "The cleaned data we create here will be used in the next notebook for exploring patterns and building models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edde1b9-a127-47ed-aeea-8e806d2ddf54",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a26b0-a570-4fc3-9587-b6c2e4bb06bd",
   "metadata": {},
   "source": [
    "## Setup And Load Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966b09a-978f-42f5-8d00-6a7df0f3a3eb",
   "metadata": {},
   "source": [
    "To get started, we need to set up our working environment. For this, we use some helper functions that we have created and stored in a folder called utils. These helper functions help us:\n",
    "- Create folders to keep the project organized (such as data, models, plots, and reports)\n",
    "- Apply default chart styles using Seaborn\n",
    "- Load datasets and quickly explore them\n",
    "\n",
    "Along with that, we also import common libraries like Pandas, NumPy, Seaborn and Matplotlib, which we will be using throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "706074f3-c0d0-4682-bf64-f3db6e248616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete.\n",
      "All libraries imported and environment initialized.\n"
     ]
    }
   ],
   "source": [
    "# We are adding the parent folder to the Python path so we can import files from the \"utils\" folder\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Importing the custom helper functions from our project\n",
    "from utils.setup_notebook import (\n",
    "    init_environment,\n",
    "    load_csv,\n",
    "    print_shape,\n",
    "    print_info,\n",
    "    print_full_info,\n",
    "    print_description,\n",
    "    print_categorical_description,\n",
    "    show_head\n",
    ")\n",
    "from utils.save_tools import save_plot, save_notebook_and_summary\n",
    "\n",
    "# Importing commonly used libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Running environment setup\n",
    "init_environment()\n",
    "print(\"All libraries imported and environment initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10118cd-f219-4301-9059-2eba154f18ca",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a3e68-fe2a-44b8-9739-d4b0dff28930",
   "metadata": {},
   "source": [
    "## Extract – Load the Dataset\n",
    "\n",
    "In this step, we load the raw Alzheimer's dataset into our project using a custom helper function from our setup.py script. The dataset has not yet been cleaned or processed, this is the original version as collected.\n",
    "Our helper function uses pandas to read the CSV file and automatically provides basic metadata. \n",
    "\n",
    "### Including:\n",
    "- The file path from which the data was loaded.  \n",
    "- The number of rows and columns present in the dataset.  \n",
    "\n",
    "This step ensures that we have successfully accessed the correct dataset and gives us an initial understanding of its structure and scale before we proceed with cleaning and transformation. To keep the original intact, a working copy is also created. This ensures we can freely clean, explore, and manipulate the data without altering the raw file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6892794d-b69e-43aa-b106-629450f312a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from ../data/alzheimers_disease_raw_data.csv with shape (2149, 35)\n",
      "Copy of df_raw dataset created as 'df' succesfully\n"
     ]
    }
   ],
   "source": [
    "# We load the raw Alzheimer's dataset and save it as 'df_raw'\n",
    "df_raw = load_csv(\"../data/alzheimers_disease_raw_data.csv\")\n",
    "\n",
    "# Then create a working copy to avoid modifying the raw dataset directly\n",
    "df = df_raw.copy()\n",
    "print(\"Copy of df_raw dataset created as 'df' succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751db888-3016-4409-9515-2043a108d2fd",
   "metadata": {},
   "source": [
    "Thereafter save the working copy of the dataset to the project folder. This allows us to reuse it later without reloading or reprocessing the raw data each time. It also keeps the original dataset unchanged in case we need to go back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ad315d-a206-4b8e-8726-9c0c9a02c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ../data/alzheimers_raw_copy.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the copy of the dataset for future steps\n",
    "df.to_csv(\"../data/alzheimers_raw_copy.csv\", index=False)\n",
    "print(\"Dataset saved to ../data/alzheimers_raw_copy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dffddc-6746-4f50-adba-2699b71fac3c",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4dd86b-a144-42b1-a1d9-7a353df01bb1",
   "metadata": {},
   "source": [
    "### ELT Approach: Extract → Load → Transform\n",
    "\n",
    "In this project, we follow the ELT (Extract, Load, Transform) process to prepare the Alzheimer’s dataset for analysis and modeling.\n",
    "- **Extract**: We begin by accessing the raw dataset, which is provided in CSV format.\n",
    "- **Load**: Using pandas, we load the dataset into memory so it can be explored and manipulated.\n",
    "- **Transform**: We then clean and organize the data by checking for duplicates, handling missing values, removing unnecessary ID columns, and grouping features by type. These steps make the dataset ready for machine learning.\n",
    "\n",
    "This approach reflects a modern data workflow, where raw data is loaded first and then transformed in memory. It allows for faster iteration, flexible processing, and better reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b047e-20d7-4bff-8313-a0053f0c74ce",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c77cd4-1a51-4160-949b-70beae9f90e2",
   "metadata": {},
   "source": [
    "## Alternative Approach – Load Libraries\n",
    "\n",
    "Before we can work with the data, we need to import the necessary Python libraries:\n",
    "\n",
    "- **pandas** is used for handling tabular data (structured data in rows and columns, like a spreadsheet). It helps us load, clean, and manage datasets.\n",
    "- **numpy** is used for numerical operations, especially with arrays and mathematical functions.\n",
    "- **matplotlib.pyplot** and **seaborn** are used for visualizing data through plots and charts.\n",
    "\n",
    "After importing the libraries, we use `read_csv()` to load the dataset into a DataFrame called `df`, and use `head()` to preview the first five rows.\n",
    "\n",
    "This setup step is important because it gives us the tools needed for cleaning, exploring, and later modeling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "167f1374-baec-465e-998a-6e768a69617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported and environment initialized.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"All libraries imported and environment initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c2573d-a584-40a7-95cd-c8b5b46fa400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# We load the dataset\n",
    "dataframe = pd.read_csv(\"../data/alzheimers_disease_raw_data.csv\")\n",
    "print(\"Dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fdcd18-d70f-4406-86f5-50f13e852e33",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ed287",
   "metadata": {},
   "source": [
    "## Initial Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a11f1",
   "metadata": {},
   "source": [
    "Now that the dataset is loaded and saved as a dataframe, we begin performing an initial inspection to understand the structure and contents. This helps us identify potential issues early and plan the cleaning steps that follow. We focus on:\n",
    "- The number of rows and columns in dataframe.\n",
    "- The data types of each column.\n",
    "- The presence of missing values.\n",
    "- Descriptive statistics for both numeric and categorical variables.\n",
    "- A sample of the first 5 rows for quick overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36314772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows and columns in the dataframe\n",
    "print_shape(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdbbd9",
   "metadata": {},
   "source": [
    "#### Dataset Dimensions\n",
    "The dataset contains 2,149 rows and 35 columns. Each row represents one patient, and each column provides a specific clinical, lifestyle, or cognitive feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a881ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data types and non-null counts for each column\n",
    "print_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51690f",
   "metadata": {},
   "source": [
    "#### Data Types and Completeness\n",
    "All 35 columns are fully populated, meaning there are no missing values in any part of the dataset.\n",
    "The data types are mostly numeric:\n",
    "\n",
    "- 22 columns are stored as integers (0 or 1 for yes/no values).\n",
    "- 12 columns are float values, which allow decimals.\n",
    "- 1 column (DoctorInCharge) is a text field and not needed for modeling.\n",
    "\n",
    "This structure makes the data ready for analysis without needing to fill or drop missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View full dataset structure with memory usage and types\n",
    "print_full_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea1f3f",
   "metadata": {},
   "source": [
    "#### Memory and Structure\n",
    "The dataset uses about 587 KB of memory, which is very manageable for analysis in a local environment.\n",
    "Each column has the correct data type, and pandas has successfully recognized the structure. This means no extra type conversions are required at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d39baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics for all variables (numeric and categorical)\n",
    "print_description(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbea447",
   "metadata": {},
   "source": [
    "### Key Statistics and Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c1ff3",
   "metadata": {},
   "source": [
    "Looking at the data more closely helps us see patterns and differences between patients. This step is useful for figuring out which features might help us predict Alzheimer’s and which ones might need extra processing later (like adjusting the scale or changing the format).\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **Age**: Most patients are between 60 and 90 years old, with an average age of about 75. This makes sense since Alzheimer’s mostly affects older adults.\n",
    "\n",
    "- **BMI (Body Mass Index)**: The average BMI is around 27.7, which falls in the overweight range. Since weight can affect both physical and brain health, BMI might be an important feature in our predictions.\n",
    "\n",
    "- **Alcohol Consumption**: On average, patients drink about 10 units of alcohol per week. Some drink more, some less. This difference could matter when we look at lifestyle risk factors.\n",
    "\n",
    "- **Blood Pressure (Systolic and Diastolic)**: The blood pressure numbers look normal for older adults, but there’s quite a bit of variation. That could be important since heart health is linked to brain health.\n",
    "\n",
    "- **Cholesterol Levels**: These also vary a lot between people:\n",
    "  - **Total cholesterol:** Average is about 225 mg/dL  \n",
    "  - **LDL (bad cholesterol):** About 124 mg/dL  \n",
    "  - **HDL (good cholesterol):** Around 59 mg/dL  \n",
    "  - **Triglycerides:** These have the widest range and highest average, which might show differences in metabolism between patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63203103",
   "metadata": {},
   "source": [
    "\n",
    "- **MMSE Scores**: These scores, which check memory and thinking, range from 0 to 30. The average score is around 14.7, which means many patients show signs of cognitive decline.\n",
    "\n",
    "- **Binary Medical Conditions**: Things like Diabetes, Depression, and Hypertension are shown as 0 (no) or 1 (yes). These conditions may increase the risk of Alzheimer’s and can be useful in prediction.\n",
    "\n",
    "By reviewing the distributions and summary statistics, we get an early sense of which variables might be strong predictors, which ones are well-behaved, and whether we need to prepare the data in any special way (like removing outliers or standardizing ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first few rows to understand how values are structured\n",
    "show_head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed585a",
   "metadata": {},
   "source": [
    "#### First 5 rows overview\n",
    "**The first five rows show that:**\n",
    "- All values are properly formatted.\n",
    "- Column names and values are clearly labeled.\n",
    "- There's good variety in the data—no obvious errors, typos, or missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ff07c",
   "metadata": {},
   "source": [
    "## Indentify Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary of categorical columns \n",
    "print_categorical_description(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd1677",
   "metadata": {},
   "source": [
    "This helps us understand non-numeric features (e.g., DoctorInCharge). In our case, this column holds anonymized IDs and won't be used for modeling, but it’s good practice to review these separately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a65983",
   "metadata": {},
   "source": [
    "## Understanding the Columns\n",
    "\n",
    "Before cleaning or analyzing the data, we need to know what each column represents. This is a key part of **data exploration** in Business Intelligence. By understanding the **data types** and what the values mean, we avoid making wrong decisions. This follows the **GIGO principle**: *Garbage In, Garbage Out*. If the input data is poor or unclear, the results will also be poor, no matter how advanced the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8e733",
   "metadata": {},
   "source": [
    "### Column Overview\n",
    "\n",
    "- **PatientID** – *ID* – A unique number for each patient. Not used for prediction.  \n",
    "- **Age** – *Numeric* – The patient's age in years.  \n",
    "- **Gender** – *Categorical* – 0 = Female, 1 = Male.  \n",
    "- **Ethnicity** – *Categorical* – Example: 0 = White, 1 = Black, etc.  \n",
    "- **EducationLevel** – *Ordinal* – Higher number means more education.  \n",
    "- **BMI** – *Numeric* – Body Mass Index (based on height and weight). \n",
    "- **Smoking** – *Binary* – 0 = No, 1 = Yes.  \n",
    "- **AlcoholConsumption** – *Numeric* – Amount of alcohol used.  \n",
    "- **PhysicalActivity** – *Numeric* – How active the person is.\n",
    "- **DietQuality** – *Numeric* – Higher number = healthier diet.  \n",
    "- **ADL** – *Numeric* – Level of help needed with daily tasks.  \n",
    "- **Diagnosis** – *Target label* – 0 = No Alzheimer’s, 1 = Alzheimer’s.  \n",
    "\n",
    "Other columns like **Confusion**, **MemoryComplaints**, and **PersonalityChanges** are binary symptoms: 0 = No, 1 = Yes.\n",
    "\n",
    "#### Why this is important\n",
    "If we do not understand what the data means, we can not clean it or use it properly. This step helps us avoid wrong assumptions and prepares the data for meaningful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419c376",
   "metadata": {},
   "source": [
    "### Column Types and Unique Values\n",
    "\n",
    "Now we check two important things about the columns:\n",
    "\n",
    "1. **Data types** – Shows if values are stored as numbers (integers, floats) or as text.  \n",
    "   For example, age should be numeric, while gender might be text or category codes.\n",
    "\n",
    "2. **Unique values** – Tells how many different values exist in each column.  \n",
    "   This helps identify which columns are categories (like gender or smoking) and which might be IDs (like PatientID), which are not useful for prediction.\n",
    "\n",
    "These checks guide decisions on which columns to keep, transform, or remove later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2ddcd",
   "metadata": {},
   "source": [
    "### Check Column Types\n",
    "Before we clean or transform any columns, we need to check the data types to understand how each variable is stored. This helps us spot which columns are numeric, which are categorical, and whether anything needs to be converted.\n",
    "This is an important part of data exploration. If we do not know what kind of data we are working with, we might handle it the wrong way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types for each column to understand variable types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51e768",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "We see that most columns in the dataset are either stored as int64 or float64, meaning they contain numerical values. This is good because numerical data can be used directly in many types of analysis and machine learning models. We also notice that one column, DoctorInCharge, is stored as an object. This usually means it contains text or categorical labels.\n",
    "\n",
    "We interpret this as a mostly numerical dataset, which is a good starting point for further processing. We also conclude that some columns, like PatientID and DoctorInCharge, are probably identifiers and not useful as features. These will likely be removed later to avoid adding irrelevant information to our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a71322",
   "metadata": {},
   "source": [
    "## Unique values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique values in each column\n",
    "# Helps identify categorical variables and ID-like columns\n",
    "df.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adc9a1",
   "metadata": {},
   "source": [
    "#### What We Learned from Unique Values: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44f11a",
   "metadata": {},
   "source": [
    "Understanding the number of unique values in each column helps us decide how to handle the data later on. Since the goal of this project is to analyze and predict Alzheimer's diagnoses based on patient characteristics, we need to be clear about which features are useful for that purpose.\n",
    "\n",
    "- PatientID has a unique value for every row, which makes it an identifier. It’s not related to the diagnosis or any medical condition, so it would not help with predictions. We'll remove it during cleaning.\n",
    "\n",
    "- Some columns like Gender, Smoking, and Diabetes only have two unique values. These are called binary variables and are usually coded as 0 and 1, for example, 0 might mean “no” and 1 might mean “yes.” These features are important because they can show risk factors or medical conditions linked to Alzheimer’s. However, even if a column has only two values, we should always check what those values actually mean. For instance, in the Gender column, 0 might mean “Female” and 1 might mean “Male,” so it’s not a simple yes/no. We will inspect value distributions during exploratory analysis to confirm their meaning.\n",
    "\n",
    "- Columns like Age, BMI, MMSE, and CholesterolTotal have many unique values. These are continuous numeric variables, meaning they can show subtle differences between patients. This kind of data is very useful for modeling, but it often needs to be scaled so that features with large values don’t dominate the model.\n",
    "\n",
    "- Diagnosis also has two unique values: 0 and 1. This is our target variable. Everything else in the dataset helps us try to predict this outcome.\n",
    "\n",
    "We’re organizing the data this way because each type of variable requires different handling in preprocessing. Binary features might be used as-is, continuous features might need scaling, and ID columns should be removed entirely. By doing this upfront, we make sure our data is well-structured and meaningful, which is essential before we move on to any analysis or modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
